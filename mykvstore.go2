package shardctrler

import (
	"bytes"
	"fmt"
	"log"
	"sync"
	"sync/atomic"
	"time"

	"6.824/labgob"
	"6.824/labrpc"
	"6.824/raft"
)

func (kv *KVStore_RSMState) PerformActions(op *KVStore_OperationDescriptor, ret *KVStore_ReturnValueDescriptor) {
	ret.ValidID = op.ValidID
	switch op.ValidID {

	}
}

type KVStore_OperationDescriptor struct {
	ValidID int
}

type KVStore_ReturnValueDescriptor struct {
	ValidID int
}

type KVStore_State struct {
	Store map[string]string
}

func New_KVStore_State() KVStore_State {
	return KVStore_State{
		Store: make(map[string]string),
	}
}

// Template below. No modification needed.

type KVStore_Op struct {
	RealOp       KVStore_OperationDescriptor
	ClientId     int64
	ClientSerial int64
}

type KVStore_EventResponse struct {
	IsOk               bool
	IsAlreadyCommitted bool
	IsClearedRequest   bool
	IsKilled           bool
	Value              KVStore_ReturnValueDescriptor
}

type KVStore_EventOp struct {
	req *KVStore_Op
	res chan KVStore_EventResponse
}

type KVStore_RSMState struct {
	State                      KVStore_State
	CommittedIndicesDontAccess map[int64]int64
}

func (kv *KVStore_RSMState) getCommittedIndex(clientId int64) int64 {
	val, ok := kv.CommittedIndicesDontAccess[clientId]
	if ok {
		return val
	} else {
		return -1
	}
}

func (kv *KVStore_RSMState) serialize() []byte {
	w := new(bytes.Buffer)
	e := labgob.NewEncoder(w)
	e.Encode(*kv)
	data := w.Bytes()
	return data
}

func KVStore_deserializeKVStore(data []byte) *KVStore_RSMState {
	newStore := KVStore_RSMState{}
	r := bytes.NewBuffer(data)
	d := labgob.NewDecoder(r)
	if d.Decode(&newStore) != nil {
		panic("Bad state")
	}
	return &newStore
}

type KVStore_ApplyLogResult struct {
	status string
	value  KVStore_ReturnValueDescriptor
}

// this is a pure function.
// deterministic state transfer here.
func (kv *KVStore_RSMState) applyLog(log *KVStore_Op) KVStore_ApplyLogResult {
	result := KVStore_ApplyLogResult{
		status: "Ok",
		value:  KVStore_ReturnValueDescriptor{},
	}
	if log.ClientSerial <= kv.getCommittedIndex(log.ClientId) {
		// already committed
		result.status = "Outdated"
		return result
	}
	kv.PerformActions(&log.RealOp, &result.value)
	/* KVStore_ApplyLogOperation_Begin */
	/* KVStore_ApplyLogOperation_End */
	kv.CommittedIndicesDontAccess[log.ClientId] = log.ClientSerial
	return result
}

type KVStore_ClientReq struct {
	ClientId     int64
	ClientSerial int64
}
type KVStore_ReplicatedStateMachine struct {
	mu      sync.Mutex
	me      int
	rf      *raft.Raft
	applyCh chan raft.ApplyMsg
	rwdead  sync.RWMutex
	dead    int32 // set by Kill()

	maxraftstate int // snapshot if log grows this big

	// Your definitions here.
	kvstore         *KVStore_RSMState
	eventQueue      chan KVStore_EventOp
	killChannel     chan int
	lastSeenTerm    int
	pendingRequests map[KVStore_ClientReq]chan KVStore_EventResponse
	persister       *raft.Persister
}

const (
	KVStore_TraceEnabled       = true
	KVStore_ClientTraceEnabled = false
)

func (kv *KVStore_ReplicatedStateMachine) tracef(msg string, args ...interface{}) {
	if KVStore_TraceEnabled {
		m := fmt.Sprintf(msg, args...)
		now := time.Now()
		fmt.Printf("[KvSt][%d-%d-%d-%d][%d] %s\n", now.Hour(), now.Minute(), now.Second(), now.Nanosecond(), kv.me, m)
	}
}

func (kv *KVStore_ReplicatedStateMachine) pushEvent(ev KVStore_EventOp) bool {
	kv.rwdead.RLock()
	flag := false
	if !kv.killed() {
		kv.eventQueue <- ev
		flag = true
	}
	kv.rwdead.RUnlock()
	return flag
}

type KVStore_ActionArgs struct {
	RealOp       KVStore_OperationDescriptor
	ClientId     int64
	ClientSerial int64
}
type KVStore_ActionReply struct {
	Value KVStore_ReturnValueDescriptor
	Err   Err
}

func (kv *KVStore_ReplicatedStateMachine) KVStore_Action(args *KVStore_ActionArgs, reply *KVStore_ActionReply) {
	//kv.tracef("Get Req %+v", *args)
	req := KVStore_Op{
		RealOp:       args.RealOp,
		ClientId:     args.ClientId,
		ClientSerial: args.ClientSerial,
	}
	responseChannel := make(chan KVStore_EventResponse, 1)
	event := KVStore_EventOp{
		req: &req,
		res: responseChannel,
	}
	success := kv.pushEvent(event)
	if !success {
		reply.Err = ErrKilled
		return
	}
	result := <-responseChannel
	if result.IsAlreadyCommitted {
		reply.Err = ErrOutdatedOp
		return
	} else if result.IsOk {
		reply.Value = result.Value
		reply.Err = OK
		return
	} else {
		if result.IsClearedRequest {
			reply.Err = ErrButItIsYouWhoTimedoutFirst
		} else if result.IsKilled {
			reply.Err = ErrKilled
		} else {
			reply.Err = ErrWrongLeader
		}
		return
	}
}

func (kv *KVStore_ReplicatedStateMachine) Kill() {
	kv.rwdead.Lock()
	atomic.StoreInt32(&kv.dead, 1)
	kv.rf.Kill()
	kv.killChannel <- 114514
	kv.rwdead.Unlock()
	// Your code here, if desired.
}

func (kv *KVStore_ReplicatedStateMachine) killed() bool {
	z := atomic.LoadInt32(&kv.dead)
	return z == 1
}

func (kv *KVStore_ReplicatedStateMachine) performRaft(log *KVStore_Op) (bool, bool, int) {
	index, observedTerm, isLeader := kv.rf.Start(*log)
	termUpdated := observedTerm > kv.lastSeenTerm
	//kv.tracef("Term check (raft) %d->%d", kv.lastSeenTerm, observedTerm)
	if observedTerm > kv.lastSeenTerm {
		kv.lastSeenTerm = observedTerm
	}
	return isLeader, termUpdated, index
}

// Returns OK, ErrWrongLeader or ErrOutdatedGet.
func (kv *KVStore_ReplicatedStateMachine) tryPerformRaftAndClearup(log *KVStore_Op, res chan KVStore_EventResponse) (bool, int) {
	if kv.kvstore.getCommittedIndex(log.ClientId) >= log.ClientSerial {
		res <- KVStore_EventResponse{IsAlreadyCommitted: true}
	}
	reqID := KVStore_ClientReq{ClientId: log.ClientId, ClientSerial: log.ClientSerial}
	val, ok := kv.pendingRequests[reqID]
	if ok {
		val <- KVStore_EventResponse{IsClearedRequest: true}
		delete(kv.pendingRequests, reqID)
	}
	isLeader, termUpdated, index := kv.performRaft(log)
	if termUpdated {
		kv.clearPendingRequestsByTermChange()
	}
	if !isLeader {
		//kv.tracef("Not leader")
		res <- KVStore_EventResponse{}
		return false, 0
	}
	kv.tracef("A new request %+v", *log)

	kv.pendingRequests[reqID] = res
	return true, index
}

func (kv *KVStore_ReplicatedStateMachine) clearPendingRequestsByTermChange() {
	m := kv.pendingRequests
	for _, ch := range m {
		ch <- KVStore_EventResponse{}
	}
	kv.pendingRequests = make(map[KVStore_ClientReq]chan KVStore_EventResponse)
}
func (kv *KVStore_ReplicatedStateMachine) printAllPendingRequests(term int) {
	keys := make([]KVStore_ClientReq, 0, len(kv.pendingRequests))
	for k := range kv.pendingRequests {
		keys = append(keys, k)
	}
	kv.tracef("Pending requests for term %d: %+v", term, keys)
}
func (kv *KVStore_ReplicatedStateMachine) eventLoop() {
	duration := 100 * time.Millisecond
	checkTerm := time.After(duration)
MAIN_LOOP:
	for !kv.killed() {
		select {
		case <-checkTerm:
			if kv.killed() {
				break MAIN_LOOP
			}
			newTerm, _ := kv.rf.GetState()
			//kv.tracef("Term check (100ms) %d->%d", kv.lastSeenTerm, newTerm)
			if newTerm > kv.lastSeenTerm {
				kv.lastSeenTerm = newTerm
				kv.clearPendingRequestsByTermChange()
			}
			kv.printAllPendingRequests(newTerm)
			checkTerm = time.After(duration)
		case ev := <-kv.eventQueue:
			if kv.killed() {
				break MAIN_LOOP
			}
			kv.tryPerformRaftAndClearup(ev.req, ev.res)
		case msg := <-kv.applyCh:
			if kv.killed() {
				break MAIN_LOOP
			}
			if msg.CommandValid == msg.SnapshotValid {
				log.Panicln("bad apply packet")
			}
			if msg.CommandValid {
				switch op := msg.Command.(type) {
				case KVStore_Op:
					if !(msg.CommandValid && (!msg.SnapshotValid)) {
						log.Panic("Bad state")
					}

					ret := kv.kvstore.applyLog(&op)
					kv.tracef("Applying op %+v = %+v", op, ret)
					reqID := KVStore_ClientReq{ClientId: op.ClientId, ClientSerial: op.ClientSerial}
					val, ok := kv.pendingRequests[reqID]
					if ok {
						if ret.status == "Outdated" {
							val <- KVStore_EventResponse{IsAlreadyCommitted: true}
						} else {
							val <- KVStore_EventResponse{IsOk: true, Value: ret.value}
						}

						delete(kv.pendingRequests, reqID)
					}
					// try to take snapshot for every applied item
					if kv.maxraftstate > 0 {
						raftSize := kv.persister.RaftStateSize()
						if raftSize >= kv.maxraftstate {
							kv.tracef("Taking snapshot since raftSize = %d, greater than %d", raftSize, kv.maxraftstate)
							kv.rf.Snapshot(msg.CommandIndex, kv.kvstore.serialize())
						}
					}

				default:
					log.Panic("Bad applied ch")
				}
			}
			if msg.SnapshotValid {
				shouldInstall := kv.rf.CondInstallSnapshot(msg.SnapshotTerm, msg.SnapshotIndex, msg.Snapshot)
				if shouldInstall {
					// snapshot installation can be seen as installing a bunch of logs.
					kv.kvstore = KVStore_deserializeKVStore(msg.Snapshot)
				}
			}
			newTerm, _ := kv.rf.GetState()
			//kv.tracef("Term check (apply) %d->%d", kv.lastSeenTerm, newTerm)
			if newTerm > kv.lastSeenTerm {
				kv.lastSeenTerm = newTerm
				kv.clearPendingRequestsByTermChange()
			} else {
				// in either case, remove overcommitted request.
				newPendingRequests := make(map[KVStore_ClientReq]chan KVStore_EventResponse)
				// remove overcommitted request
				for reqID, ch := range kv.pendingRequests {
					if kv.kvstore.getCommittedIndex(reqID.ClientId) >= reqID.ClientSerial {
						ch <- KVStore_EventResponse{IsAlreadyCommitted: true}
					} else {
						newPendingRequests[reqID] = ch
					}
				}
				kv.pendingRequests = newPendingRequests
			}

		case <-kv.killChannel:
			kv.tracef("External killed")
			break MAIN_LOOP
		}
	}
	kv.tracef("Graceful killed")
GRACEFUL_SHUTDOWN:
	for {
		select {
		case remainEv := <-kv.eventQueue:
			remainEv.res <- KVStore_EventResponse{IsKilled: true}
		default:
			break GRACEFUL_SHUTDOWN
		}
	}
	for _, pending := range kv.pendingRequests {
		pending <- KVStore_EventResponse{IsKilled: true}
	}
}

//
// servers[] contains the ports of the set of
// servers that will cooperate via Raft to
// form the fault-tolerant key/value service.
// me is the index of the current server in servers[].
// the k/v server should store snapshots through the underlying Raft
// implementation, which should call persister.SaveStateAndSnapshot() to
// atomically save the Raft state along with the snapshot.
// the k/v server should snapshot when Raft's saved state exceeds maxraftstate bytes,
// in order to allow Raft to garbage-collect its log. if maxraftstate is -1,
// you don't need to snapshot.
// StartKVServer() must return quickly, so it should start goroutines
// for any long-running work.
//
func KVStore_StartServer(servers []*labrpc.ClientEnd, me int, persister *raft.Persister, maxraftstate int) *KVStore_ReplicatedStateMachine {
	// call labgob.Register on structures you want
	// Go's RPC library to marshall/unmarshall.
	labgob.Register(KVStore_Op{})

	kv := new(KVStore_ReplicatedStateMachine)
	kv.me = me
	kv.maxraftstate = maxraftstate

	// You may need initialization code here.

	kv.applyCh = make(chan raft.ApplyMsg)
	kv.rf = raft.Make(servers, me, persister, kv.applyCh)

	kv.persister = persister
	snapshot := kv.persister.ReadSnapshot()

	if snapshot != nil && len(snapshot) != 0 {
		kv.kvstore = KVStore_deserializeKVStore(snapshot)
	} else {
		kv.kvstore = &KVStore_RSMState{State: New_KVStore_State(),
			CommittedIndicesDontAccess: make(map[int64]int64)}
	}

	kv.eventQueue = make(chan KVStore_EventOp)
	kv.killChannel = make(chan int, 1)
	kv.lastSeenTerm = -1
	kv.pendingRequests = make(map[KVStore_ClientReq]chan KVStore_EventResponse)
	kv.dead = 0

	// You may need initialization code here.
	go kv.eventLoop()
	return kv
}

type KVStore_Clerk struct {
	servers                                     []*labrpc.ClientEnd
	lastLeader                                  int
	clientId                                    int64
	clientSerial                                int64
	lockSoThatClientWillNotSendMultipleRequests sync.Mutex
	// You will have to modify this struct.
}

func (ck *KVStore_Clerk) getNextSerial() int64 {
	serial := ck.clientSerial
	ck.clientSerial++
	return serial
}

func KVStore_MakeClerk(servers []*labrpc.ClientEnd) *KVStore_Clerk {
	ck := new(KVStore_Clerk)
	ck.servers = servers
	ck.clientSerial = 0
	ck.clientId = nrand()
	ck.lastLeader = 0
	// You'll have to add code here.
	return ck
}

func (ck *KVStore_Clerk) tracef(msg string, args ...interface{}) {
	if KVStore_ClientTraceEnabled {
		m := fmt.Sprintf(msg, args...)
		now := time.Now()
		fmt.Printf("[KvCl][%d-%d-%d-%d][%d] %s\n", now.Hour(), now.Minute(), now.Second(), now.Nanosecond(), ck.clientId, m)
	}
}

func (ck *KVStore_Clerk) PerformGeneralAction(op KVStore_OperationDescriptor) (*KVStore_ReturnValueDescriptor, bool) {
	ck.lockSoThatClientWillNotSendMultipleRequests.Lock()
	defer ck.lockSoThatClientWillNotSendMultipleRequests.Unlock()
	leader := ck.lastLeader
	args := KVStore_ActionArgs{RealOp: op, ClientId: ck.clientId, ClientSerial: ck.getNextSerial()}
	reply := KVStore_ActionReply{}
	ck.tracef("Sending request %+v", args)
OP_LOOP:
	for {
		ck.tracef("Trying server %d", leader)
		ok := ck.servers[leader].Call("KVStore_ReplicatedStateMachine.KVStore_Action", &args, &reply)
		if !ok {
			ck.tracef("Sending request %+v failed.", args)
			leader++
			if leader >= len(ck.servers) {
				leader = 0
			}
			continue // try again
		}
		switch reply.Err {
		case OK:
			break OP_LOOP
		case ErrKilled:
			ck.tracef("Killed")
			reply = KVStore_ActionReply{}
			leader++
			if leader >= len(ck.servers) {
				leader = 0
			}
		case ErrWrongLeader:
			ck.tracef("Wrong leader")
			reply = KVStore_ActionReply{}
			leader++
			if leader >= len(ck.servers) {
				leader = 0
			}
		case ErrOutdatedOp:
			return nil, true
		case ErrButItIsYouWhoTimedoutFirst:
			log.Panicln("This should not happen.")
		}
	}

	ck.lastLeader = leader
	val := reply.Value
	return &val, false
}
